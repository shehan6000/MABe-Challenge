import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# For modeling
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import GroupKFold
import lightgbm as lgb
from scipy.ndimage import gaussian_filter1d
from collections import defaultdict

# ============================================================================
# CONFIGURATION
# ============================================================================

class Config:
    """Configuration parameters"""
    DATA_PATH = Path('/kaggle/input/mabe-challenge-social-action-recognition-mice')
    TRAIN_TRACKING_PATH = DATA_PATH / 'train_tracking'
    TEST_TRACKING_PATH = DATA_PATH / 'test_tracking'
    TRAIN_ANNOTATION_PATH = DATA_PATH / 'train_annotation'
    
    # Model parameters
    WINDOW_SIZE = 30  # frames to look at (past and future context)
    STRIDE = 5  # stride for sliding window
    MIN_BEHAVIOR_DURATION = 3  # minimum frames for a behavior
    CONFIDENCE_THRESHOLD = 0.5
    
    # Cross-validation
    N_FOLDS = 5
    RANDOM_STATE = 42

# ============================================================================
# DATA LOADING
# ============================================================================

def load_metadata():
    """Load train and test metadata"""
    train_meta = pd.read_csv(Config.DATA_PATH / 'train.csv')
    test_meta = pd.read_csv(Config.DATA_PATH / 'test.csv')
    print(f"Train videos: {len(train_meta)}, Test videos: {len(test_meta)}")
    return train_meta, test_meta

def load_tracking_data(video_id, is_train=True):
    """Load tracking data for a specific video"""
    path = Config.TRAIN_TRACKING_PATH if is_train else Config.TEST_TRACKING_PATH
    file_path = path / f"{video_id}.parquet"
    
    if file_path.exists():
        df = pd.read_parquet(file_path)
        return df
    return None

def load_annotations(video_id):
    """Load annotation data for a specific video"""
    file_path = Config.TRAIN_ANNOTATION_PATH / f"{video_id}.parquet"
    if file_path.exists():
        df = pd.read_parquet(file_path)
        return df
    return None

# ============================================================================
# FEATURE ENGINEERING
# ============================================================================

class FeatureExtractor:
    """Extract features from pose tracking data"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.fitted = False
    
    def extract_spatial_features(self, df):
        """Extract spatial features from tracking data"""
        features = {}
        
        # Get unique mice and body parts
        mice = df['mouse_id'].unique()
        body_parts = df['bodypart'].unique()
        
        # Pivot data for easier access
        pivot = df.pivot_table(
            index=['video_frame', 'mouse_id'],
            columns='bodypart',
            values=['x', 'y']
        ).reset_index()
        
        # Flatten column names
        pivot.columns = ['_'.join(col).strip('_') if col[0] not in ['video_frame', 'mouse_id'] 
                        else col[0] for col in pivot.columns]
        
        return pivot
    
    def compute_pairwise_features(self, df):
        """Compute features between pairs of mice"""
        features_list = []
        
        for frame in df['video_frame'].unique():
            frame_data = df[df['video_frame'] == frame]
            mice = frame_data['mouse_id'].unique()
            
            # For each pair of mice
            for i, mouse1 in enumerate(mice):
                for mouse2 in mice:
                    if mouse1 == mouse2:
                        continue
                    
                    m1_data = frame_data[frame_data['mouse_id'] == mouse1]
                    m2_data = frame_data[frame_data['mouse_id'] == mouse2]
                    
                    if len(m1_data) == 0 or len(m2_data) == 0:
                        continue
                    
                    # Compute centroid for each mouse
                    m1_x, m1_y = m1_data['x'].mean(), m1_data['y'].mean()
                    m2_x, m2_y = m2_data['x'].mean(), m2_data['y'].mean()
                    
                    # Distance between mice
                    distance = np.sqrt((m1_x - m2_x)**2 + (m1_y - m2_y)**2)
                    
                    # Relative angle
                    angle = np.arctan2(m2_y - m1_y, m2_x - m1_x)
                    
                    features_list.append({
                        'video_frame': frame,
                        'agent_id': mouse1,
                        'target_id': mouse2,
                        'distance': distance,
                        'angle': angle,
                        'm1_x': m1_x,
                        'm1_y': m1_y,
                        'm2_x': m2_x,
                        'm2_y': m2_y
                    })
        
        return pd.DataFrame(features_list)
    
    def add_temporal_features(self, df, window=5):
        """Add temporal features (velocities, accelerations)"""
        df = df.sort_values('video_frame')
        
        # Velocity (change in position)
        for col in ['m1_x', 'm1_y', 'm2_x', 'm2_y', 'distance']:
            if col in df.columns:
                df[f'{col}_velocity'] = df[col].diff()
                df[f'{col}_acceleration'] = df[f'{col}_velocity'].diff()
        
        # Rolling statistics
        for col in ['distance', 'angle']:
            if col in df.columns:
                df[f'{col}_mean_{window}'] = df[col].rolling(window, center=True).mean()
                df[f'{col}_std_{window}'] = df[col].rolling(window, center=True).std()
        
        # Fill NaN values
        df = df.fillna(0)
        
        return df
    
    def create_windows(self, df, window_size=30, stride=5):
        """Create sliding windows of features"""
        frames = sorted(df['video_frame'].unique())
        windows = []
        
        for start_frame in range(0, len(frames), stride):
            end_frame = min(start_frame + window_size, len(frames))
            window_frames = frames[start_frame:end_frame]
            
            if len(window_frames) < window_size // 2:  # Skip very short windows
                continue
            
            window_data = df[df['video_frame'].isin(window_frames)]
            
            if len(window_data) > 0:
                # Aggregate features over the window
                agg_features = {
                    'start_frame': window_frames[0],
                    'end_frame': window_frames[-1],
                    'center_frame': window_frames[len(window_frames)//2]
                }
                
                # Add aggregated statistics
                numeric_cols = window_data.select_dtypes(include=[np.number]).columns
                for col in numeric_cols:
                    if col != 'video_frame':
                        agg_features[f'{col}_mean'] = window_data[col].mean()
                        agg_features[f'{col}_std'] = window_data[col].std()
                        agg_features[f'{col}_max'] = window_data[col].max()
                        agg_features[f'{col}_min'] = window_data[col].min()
                
                # Add agent/target info if available
                if 'agent_id' in window_data.columns:
                    agg_features['agent_id'] = window_data['agent_id'].iloc[0]
                if 'target_id' in window_data.columns:
                    agg_features['target_id'] = window_data['target_id'].iloc[0]
                
                windows.append(agg_features)
        
        return pd.DataFrame(windows)

# ============================================================================
# MODEL TRAINING
# ============================================================================

class BehaviorClassifier:
    """Train behavior classification models"""
    
    def __init__(self):
        self.models = {}
        self.label_encoders = {}
        self.feature_columns = None
    
    def prepare_training_data(self, train_meta):
        """Prepare training data from all videos"""
        all_features = []
        all_labels = []
        all_video_ids = []
        
        feature_extractor = FeatureExtractor()
        
        print("Processing training videos...")
        for idx, row in train_meta.iterrows():
            video_id = row['video_id']
            
            if idx % 10 == 0:
                print(f"Processing {idx}/{len(train_meta)}: {video_id}")
            
            # Load tracking and annotations
            tracking = load_tracking_data(video_id, is_train=True)
            annotations = load_annotations(video_id)
            
            if tracking is None or annotations is None:
                continue
            
            # Extract features
            pairwise_features = feature_extractor.compute_pairwise_features(tracking)
            if len(pairwise_features) == 0:
                continue
            
            pairwise_features = feature_extractor.add_temporal_features(pairwise_features)
            
            # Create labeled windows
            for _, ann in annotations.iterrows():
                agent_id = ann['agent_id']
                target_id = ann['target_id']
                action = ann['action']
                start_frame = ann['start_frame']
                stop_frame = ann['stop_frame']
                
                # Get features for this agent-target pair during this action
                relevant_features = pairwise_features[
                    (pairwise_features['agent_id'] == agent_id) &
                    (pairwise_features['target_id'] == target_id) &
                    (pairwise_features['video_frame'] >= start_frame) &
                    (pairwise_features['video_frame'] <= stop_frame)
                ]
                
                if len(relevant_features) > 0:
                    # Use mean features for this behavior segment
                    feature_vec = relevant_features.select_dtypes(include=[np.number]).mean()
                    all_features.append(feature_vec.values)
                    all_labels.append(action)
                    all_video_ids.append(video_id)
        
        if len(all_features) == 0:
            print("No features extracted!")
            return None, None, None
        
        X = np.array(all_features)
        y = np.array(all_labels)
        video_ids = np.array(all_video_ids)
        
        print(f"Extracted {len(X)} training samples")
        print(f"Unique behaviors: {len(np.unique(y))}")
        
        return X, y, video_ids
    
    def train(self, X, y, video_ids):
        """Train LightGBM classifier"""
        
        # Encode labels
        self.label_encoder = LabelEncoder()
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Train a single model for all behaviors
        print("\nTraining classifier...")
        
        params = {
            'objective': 'multiclass',
            'num_class': len(self.label_encoder.classes_),
            'metric': 'multi_logloss',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1
        }
        
        # Simple train-test split by video
        unique_videos = np.unique(video_ids)
        train_videos = unique_videos[:int(0.8 * len(unique_videos))]
        
        train_mask = np.isin(video_ids, train_videos)
        X_train, X_val = X[train_mask], X[~train_mask]
        y_train, y_val = y_encoded[train_mask], y_encoded[~train_mask]
        
        train_data = lgb.Dataset(X_train, label=y_train)
        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
        
        self.model = lgb.train(
            params,
            train_data,
            num_boost_round=500,
            valid_sets=[train_data, val_data],
            callbacks=[lgb.early_stopping(stopping_rounds=50)]
        )
        
        print(f"Model trained. Best score: {self.model.best_score}")
    
    def predict(self, X):
        """Predict behaviors"""
        probas = self.model.predict(X, num_iteration=self.model.best_iteration)
        predictions = np.argmax(probas, axis=1)
        behaviors = self.label_encoder.inverse_transform(predictions)
        confidences = np.max(probas, axis=1)
        return behaviors, confidences

# ============================================================================
# PREDICTION & SUBMISSION
# ============================================================================

def create_submission(test_meta, model, feature_extractor):
    """Create submission file"""
    submission_rows = []
    row_id = 0
    
    print("\nGenerating predictions for test videos...")
    
    for idx, row in test_meta.iterrows():
        video_id = row['video_id']
        
        if idx % 10 == 0:
            print(f"Processing {idx}/{len(test_meta)}: {video_id}")
        
        # Load tracking data
        tracking = load_tracking_data(video_id, is_train=False)
        if tracking is None:
            continue
        
        # Extract features
        pairwise_features = feature_extractor.compute_pairwise_features(tracking)
        if len(pairwise_features) == 0:
            continue
        
        pairwise_features = feature_extractor.add_temporal_features(pairwise_features)
        
        # Get unique agent-target pairs
        pairs = pairwise_features[['agent_id', 'target_id']].drop_duplicates()
        
        for _, pair in pairs.iterrows():
            agent_id = pair['agent_id']
            target_id = pair['target_id']
            
            pair_features = pairwise_features[
                (pairwise_features['agent_id'] == agent_id) &
                (pairwise_features['target_id'] == target_id)
            ].sort_values('video_frame')
            
            if len(pair_features) == 0:
                continue
            
            # Sliding window prediction
            windows = feature_extractor.create_windows(
                pair_features, 
                window_size=Config.WINDOW_SIZE,
                stride=Config.STRIDE
            )
            
            if len(windows) == 0:
                continue
            
            # Prepare features for prediction
            X_pred = windows.select_dtypes(include=[np.number]).fillna(0).values
            
            # Predict
            behaviors, confidences = model.predict(X_pred)
            
            # Post-process: merge consecutive predictions of same behavior
            current_behavior = None
            start_frame = None
            
            for i, (behavior, conf) in enumerate(zip(behaviors, confidences)):
                if conf < Config.CONFIDENCE_THRESHOLD:
                    continue
                
                frame = int(windows.iloc[i]['center_frame'])
                
                if behavior != current_behavior:
                    # Save previous behavior
                    if current_behavior is not None and start_frame is not None:
                        submission_rows.append({
                            'row_id': row_id,
                            'video_id': video_id,
                            'agent_id': agent_id,
                            'target_id': target_id,
                            'action': current_behavior,
                            'start_frame': start_frame,
                            'stop_frame': frame
                        })
                        row_id += 1
                    
                    # Start new behavior
                    current_behavior = behavior
                    start_frame = frame
            
            # Save last behavior
            if current_behavior is not None and start_frame is not None:
                submission_rows.append({
                    'row_id': row_id,
                    'video_id': video_id,
                    'agent_id': agent_id,
                    'target_id': target_id,
                    'action': current_behavior,
                    'start_frame': start_frame,
                    'stop_frame': int(pair_features['video_frame'].max())
                })
                row_id += 1
    
    submission_df = pd.DataFrame(submission_rows)
    return submission_df

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution pipeline"""
    
    print("=" * 80)
    print("MABe Challenge - Social Action Recognition in Mice")
    print("=" * 80)
    
    # Load metadata
    train_meta, test_meta = load_metadata()
    
    # Initialize components
    classifier = BehaviorClassifier()
    feature_extractor = FeatureExtractor()
    
    # Prepare training data
    print("\n" + "=" * 80)
    print("PHASE 1: Feature Extraction")
    print("=" * 80)
    X, y, video_ids = classifier.prepare_training_data(train_meta)
    
    if X is None:
        print("Failed to extract features!")
        return
    
    # Train model
    print("\n" + "=" * 80)
    print("PHASE 2: Model Training")
    print("=" * 80)
    classifier.train(X, y, video_ids)
    
    # Create submission
    print("\n" + "=" * 80)
    print("PHASE 3: Generating Predictions")
    print("=" * 80)
    submission = create_submission(test_meta, classifier, feature_extractor)
    
    # Save submission
    submission.to_csv('submission.csv', index=False)
    print(f"\nSubmission saved! Total predictions: {len(submission)}")
    print(f"Unique videos: {submission['video_id'].nunique()}")
    print(f"Unique behaviors: {submission['action'].nunique()}")
    print("\nSample predictions:")
    print(submission.head(10))

if __name__ == "__main__":
    main()
